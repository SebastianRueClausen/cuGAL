2024-06-05 08:03:22,425 - e.ex - INFO - Running command 'main'
2024-06-05 08:03:22,433 - e.ex - INFO - Started run with ID "647"
init1
[[<function loadnx at 0x7fcccad31bc0>, [['data/ca-Erdos992.txt']]]]
<function loadnx at 0x7fcccad31bc0> ['data/ca-Erdos992.txt']
init2
C
##<1>##
4991 6100
##<1>##
4982 6100
C
##<1>##
4991 6100
##<1>##
4987 6100
C
##<1>##
4991 6100
##<1>##
4983 6100
C
##<1>##
4991 6100
##<1>##
4885 6100
C
##<1>##
4991 6100
##<1>##
4894 6100
2024-06-05 08:03:22,861 - e.main - INFO - randcheck: (0.8521051667032807, 0.3314779244583854)
runs/647
2024-06-05 08:03:22,862 - e.run_exp - INFO - Graph:(1/1)
2024-06-05 08:03:22,862 - e.run_exp - INFO - Noise_level:(1/5)
2024-06-05 08:03:22,862 - e.run_exp - INFO - iteration:(1/1)
2024-06-05 08:03:22,879 - e.run_algs - WARNING - Disc. Source: 4991 < 6100
2024-06-05 08:03:22,879 - e.run_algs - WARNING - Disc. Target: 4982 < 6100
args:  {'iter': 15, 'simple': True, 'mu': 2}
Fugal
/opt/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.
  return _methods._mean(a, axis=axis, dtype=dtype,
/opt/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)
/home/andreas.hansen/Framework_GraphAlignment_CUGAL/algorithms/FUGAL/sinkhorn.py:177: UserWarning: An output with one or more elements was resized since it had shape [6100], which does not match the required output shape [1, 6100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/Resize.cpp:28.)
  torch.matmul(u, K, out=KTu)
2024-06-05 08:24:12,683 - e.run_exp - INFO - 
[[[0.28]]]
2024-06-05 08:24:12,684 - e.run_exp - INFO - Noise_level:(2/5)
2024-06-05 08:24:12,684 - e.run_exp - INFO - iteration:(1/1)
2024-06-05 08:24:12,701 - e.run_algs - WARNING - Disc. Source: 4991 < 6100
2024-06-05 08:24:12,701 - e.run_algs - WARNING - Disc. Target: 4987 < 6100
args:  {'iter': 15, 'simple': True, 'mu': 2}
Fugal
/opt/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.
  return _methods._mean(a, axis=axis, dtype=dtype,
/opt/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)
/home/andreas.hansen/Framework_GraphAlignment_CUGAL/algorithms/FUGAL/sinkhorn.py:177: UserWarning: An output with one or more elements was resized since it had shape [6100], which does not match the required output shape [1, 6100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/Resize.cpp:28.)
  torch.matmul(u, K, out=KTu)
2024-06-05 08:45:03,491 - e.run_exp - INFO - 
[[[0.2623]]]
2024-06-05 08:45:03,491 - e.run_exp - INFO - Noise_level:(3/5)
2024-06-05 08:45:03,491 - e.run_exp - INFO - iteration:(1/1)
2024-06-05 08:45:03,508 - e.run_algs - WARNING - Disc. Source: 4991 < 6100
2024-06-05 08:45:03,508 - e.run_algs - WARNING - Disc. Target: 4983 < 6100
args:  {'iter': 15, 'simple': True, 'mu': 2}
Fugal
/opt/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.
  return _methods._mean(a, axis=axis, dtype=dtype,
/opt/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)
/home/andreas.hansen/Framework_GraphAlignment_CUGAL/algorithms/FUGAL/sinkhorn.py:177: UserWarning: An output with one or more elements was resized since it had shape [6100], which does not match the required output shape [1, 6100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/Resize.cpp:28.)
  torch.matmul(u, K, out=KTu)
2024-06-05 09:05:55,776 - e.run_exp - INFO - 
[[[0.2431]]]
2024-06-05 09:05:55,777 - e.run_exp - INFO - Noise_level:(4/5)
2024-06-05 09:05:55,777 - e.run_exp - INFO - iteration:(1/1)
2024-06-05 09:05:55,919 - e.run_algs - WARNING - Disc. Source: 4991 < 6100
2024-06-05 09:05:55,919 - e.run_algs - WARNING - Disc. Target: 4885 < 6100
args:  {'iter': 15, 'simple': True, 'mu': 2}
Fugal
/opt/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.
  return _methods._mean(a, axis=axis, dtype=dtype,
/opt/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)
/home/andreas.hansen/Framework_GraphAlignment_CUGAL/algorithms/FUGAL/sinkhorn.py:177: UserWarning: An output with one or more elements was resized since it had shape [6100], which does not match the required output shape [1, 6100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/Resize.cpp:28.)
  torch.matmul(u, K, out=KTu)
2024-06-05 09:26:48,980 - e.run_exp - INFO - 
[[[0.2254]]]
2024-06-05 09:26:48,980 - e.run_exp - INFO - Noise_level:(5/5)
2024-06-05 09:26:48,980 - e.run_exp - INFO - iteration:(1/1)
2024-06-05 09:26:48,997 - e.run_algs - WARNING - Disc. Source: 4991 < 6100
2024-06-05 09:26:48,997 - e.run_algs - WARNING - Disc. Target: 4894 < 6100
args:  {'iter': 15, 'simple': True, 'mu': 2}
Fugal
/opt/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.
  return _methods._mean(a, axis=axis, dtype=dtype,
/opt/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)
/home/andreas.hansen/Framework_GraphAlignment_CUGAL/algorithms/FUGAL/sinkhorn.py:177: UserWarning: An output with one or more elements was resized since it had shape [6100], which does not match the required output shape [1, 6100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/Resize.cpp:28.)
  torch.matmul(u, K, out=KTu)
2024-06-05 09:47:42,429 - e.run_exp - INFO - 
[[[0.2231]]]
2024-06-05 09:47:42,430 - e.ex - INFO - Completed after 1:44:20
