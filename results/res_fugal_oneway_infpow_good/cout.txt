2024-06-05 10:25:53,998 - e.ex - INFO - Running command 'main'
2024-06-05 10:25:54,006 - e.ex - INFO - Started run with ID "649"
init1
[[<function loadnx at 0x7f41f30b9bc0>, [['data/inf-power.txt']]]]
<function loadnx at 0x7f41f30b9bc0> ['data/inf-power.txt']
init2
C
##<1>##
4941 4941
##<1>##
4941 4941
C
##<1>##
4941 4941
##<1>##
4837 4941
C
##<1>##
4941 4941
##<1>##
4762 4941
C
##<1>##
4941 4941
##<1>##
4469 4941
C
##<1>##
4941 4941
##<1>##
4213 4941
C
##<1>##
4941 4941
##<1>##
1997 4941
2024-06-05 10:25:54,473 - e.main - INFO - randcheck: (0.8521051667032807, 0.35275110862737613)
runs/649
2024-06-05 10:25:54,473 - e.run_exp - INFO - Graph:(1/1)
2024-06-05 10:25:54,473 - e.run_exp - INFO - Noise_level:(1/6)
2024-06-05 10:25:54,473 - e.run_exp - INFO - iteration:(1/1)
args:  {'iter': 15, 'simple': True, 'mu': 0.5}
Fugal
/home/andreas.hansen/Framework_GraphAlignment_CUGAL/algorithms/FUGAL/sinkhorn.py:177: UserWarning: An output with one or more elements was resized since it had shape [4941], which does not match the required output shape [1, 4941]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/Resize.cpp:28.)
  torch.matmul(u, K, out=KTu)
2024-06-05 10:39:42,465 - e.run_exp - INFO - 
[[[0.9002]]]
2024-06-05 10:39:42,466 - e.run_exp - INFO - Noise_level:(2/6)
2024-06-05 10:39:42,466 - e.run_exp - INFO - iteration:(1/1)
2024-06-05 10:39:42,482 - e.run_algs - WARNING - Disc. Target: 4837 < 4941
args:  {'iter': 15, 'simple': True, 'mu': 0.5}
Fugal
/home/andreas.hansen/Framework_GraphAlignment_CUGAL/algorithms/FUGAL/sinkhorn.py:177: UserWarning: An output with one or more elements was resized since it had shape [4941], which does not match the required output shape [1, 4941]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/Resize.cpp:28.)
  torch.matmul(u, K, out=KTu)
2024-06-05 10:53:37,221 - e.run_exp - INFO - 
[[[0.6098]]]
2024-06-05 10:53:37,221 - e.run_exp - INFO - Noise_level:(3/6)
2024-06-05 10:53:37,221 - e.run_exp - INFO - iteration:(1/1)
2024-06-05 10:53:37,358 - e.run_algs - WARNING - Disc. Target: 4762 < 4941
args:  {'iter': 15, 'simple': True, 'mu': 0.5}
Fugal
/home/andreas.hansen/Framework_GraphAlignment_CUGAL/algorithms/FUGAL/sinkhorn.py:177: UserWarning: An output with one or more elements was resized since it had shape [4941], which does not match the required output shape [1, 4941]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/Resize.cpp:28.)
  torch.matmul(u, K, out=KTu)
2024-06-05 11:07:40,085 - e.run_exp - INFO - 
[[[0.3943]]]
2024-06-05 11:07:40,086 - e.run_exp - INFO - Noise_level:(4/6)
2024-06-05 11:07:40,086 - e.run_exp - INFO - iteration:(1/1)
2024-06-05 11:07:40,101 - e.run_algs - WARNING - Disc. Target: 4469 < 4941
args:  {'iter': 15, 'simple': True, 'mu': 0.5}
Fugal
/home/andreas.hansen/Framework_GraphAlignment_CUGAL/algorithms/FUGAL/sinkhorn.py:177: UserWarning: An output with one or more elements was resized since it had shape [4941], which does not match the required output shape [1, 4941]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/Resize.cpp:28.)
  torch.matmul(u, K, out=KTu)
2024-06-05 11:22:02,497 - e.run_exp - INFO - 
[[[0.1775]]]
2024-06-05 11:22:02,497 - e.run_exp - INFO - Noise_level:(5/6)
2024-06-05 11:22:02,497 - e.run_exp - INFO - iteration:(1/1)
2024-06-05 11:22:02,513 - e.run_algs - WARNING - Disc. Target: 4213 < 4941
args:  {'iter': 15, 'simple': True, 'mu': 0.5}
Fugal
/home/andreas.hansen/Framework_GraphAlignment_CUGAL/algorithms/FUGAL/sinkhorn.py:177: UserWarning: An output with one or more elements was resized since it had shape [4941], which does not match the required output shape [1, 4941]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/Resize.cpp:28.)
  torch.matmul(u, K, out=KTu)
2024-06-05 11:36:20,924 - e.run_exp - INFO - 
[[[0.1295]]]
2024-06-05 11:36:20,924 - e.run_exp - INFO - Noise_level:(6/6)
2024-06-05 11:36:20,924 - e.run_exp - INFO - iteration:(1/1)
2024-06-05 11:36:20,940 - e.run_algs - WARNING - Disc. Target: 1997 < 4941
args:  {'iter': 15, 'simple': True, 'mu': 0.5}
Fugal
/home/andreas.hansen/Framework_GraphAlignment_CUGAL/algorithms/FUGAL/sinkhorn.py:177: UserWarning: An output with one or more elements was resized since it had shape [4941], which does not match the required output shape [1, 4941]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/Resize.cpp:28.)
  torch.matmul(u, K, out=KTu)
2024-06-05 11:50:41,677 - e.run_exp - INFO - 
[[[0.0506]]]
2024-06-05 11:50:41,677 - e.ex - INFO - Completed after 1:24:48
